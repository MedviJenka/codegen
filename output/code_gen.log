DEBUG | Monday | 17/02/2025 | 10:43:03 | LiteLLM | [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm.proxy.enterprise' | Function: <module> | Line: 113
INFO | Monday | 17/02/2025 | 10:43:18 | root | Interact with the browser if needed. Close it when you're done. | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:19 | root | Navigation or context issue: Page.evaluate: Execution context was destroyed, most likely because of a navigation | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:21 | root | Navigation or context issue: Page.evaluate: Execution context was destroyed, most likely because of a navigation | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:36 | root | Navigation or context issue: Page.evaluate: Execution context was destroyed, most likely because of a navigation | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:41 | root | Navigation or context issue: Page.evaluate: Execution context was destroyed, most likely because of a navigation | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | Navigation or context issue: Page.wait_for_timeout: Target page, context or browser has been closed | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | 
Recorded Interactions: | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | [['Sign in with Microsoft 365', 'ID', 'login_button', 'Clicked on Sign in with Microsoft 365', None], ['i0116', 'ID', 'i0116', 'Clicked on input', None], ['idsibutton9', 'ID', 'idSIButton9', 'Clicked on input', None], ['checkbox_1739781823445', 'XPATH', '//*[@id="67b1c354b627305207967729-checkbox"]/span[1]/input[1]', 'Checkbox unchecked', 'off'], ['checkbox_1739781823794', 'XPATH', '//*[@id="67b1bef2b627305207967706-checkbox"]/span[1]/input[1]', 'Checkbox unchecked', 'off'], ['checkbox_1739781824220', 'XPATH', '//*[@id="67ae329cb6273052079672bf-checkbox"]/span[1]/input[1]', 'Checkbox unchecked', 'off'], ['Action', 'ID', 'call-Actions-btn', 'Clicked on Action', None], ['Export to Excel', 'ID', 'exportExcel-menuitem', 'Clicked on Export to Excel', None], ['export', 'ID', 'interactions-exportToExcel-export-btn', 'Clicked on export', None], ['a', 'XPATH', '//*[@id="root"]/a[1]', 'Clicked on a', None]] | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | 
Interactions saved to C:\Users\evgenyp\PycharmProjects\codegen\output\page_base.csv | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | 
        import pytest
from qasharedinfra.devices.audc.smarttap.smarttap import SmartTap
import coreinfra.core.environment.environment_variables as env
from coreinfra.services.selenium.mappedselenium import MappedSelenium
from coreinfra.services.selenium.seleniumwebelement import Actions

from qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils

HEADLESS = False
st: SmartTap = env.devices['Device_1']
log = env.logger


@pytest.fixture(scope='module', autouse=True)
def init_globals() -> None:

    st.logger_.info('
******** Module (Script) Setup ********')
    bini = IRBiniUtils()
    st.test_prerequisites(selenium=True, headless=HEADLESS)
    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen

    yield bini

    st.logger.info('******** Module (Script) TearDown ********')
    st.selenium.finalize()


@pytest.fixture(scope='function', autouse=True)
def setup_and_teardown() -> None:
    st.logger_.info('******** Test Setup ********')

    yield

    st.logger_.info('******** Test TearDown ********')

@pytest.fixture
def driver() -> MappedSelenium:
    return st.selenium
    
    
        class TestNone:

            def test_None(self, driver) -> None:
                driver.get_mapped_element('Sign in with Microsoft 365').action(Actions.CLICK)
driver.get_mapped_element('i0116').action(Actions.CLICK)
driver.get_mapped_element('idsibutton9').action(Actions.CLICK)
driver.get_mapped_element('Action').action(Actions.CLICK)
driver.get_mapped_element('Export to Excel').action(Actions.CLICK)
driver.get_mapped_element('export').action(Actions.CLICK)
driver.get_mapped_element('a').action(Actions.CLICK)
         | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:49 | root | python file: C:\Users\evgenyp\PycharmProjects\codegen\output\test_code.py | Function: log_info | Line: 50
INFO | Monday | 17/02/2025 | 10:43:59 | crewai.flow.flow | Flow started with ID: 60ca0b90-4c9f-4fdc-ab34-285ed18956fd | Function: _log_flow_event | Line: 1025
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | [92mRequest to litellm:[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | [92mlitellm.completion(model='azure/bini', messages=[{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], temperature=0, stop=['\nObservation:'], api_version='2024-02-15-preview', stream=False)[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>] | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | self.optional_params: {} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | Translating developer role to system role for non-OpenAI providers. | Function: translate_developer_role_to_system_role | Line: 115
INFO | Monday | 17/02/2025 | 10:43:59 | LiteLLM | 
LiteLLM completion() model= bini; provider = azure | Function: _check_valid_arg | Line: 2896
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | 
LiteLLM: Params passed to completion() {'model': 'bini', 'functions': None, 'function_call': None, 'temperature': 0, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'azure', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': '2024-02-15-preview', 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]} | Function: _check_valid_arg | Line: 2899
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | 
LiteLLM: Non-Default params passed to completion() {'temperature': 0, 'stream': False, 'stop': ['\nObservation:']} | Function: _check_valid_arg | Line: 2902
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | Azure optional params - api_version: api_version=2024-02-15-preview, litellm.api_version=None, os.environ['AZURE_API_VERSION']=2024-02-15-preview | Function: get_optional_params | Line: 3502
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | Final returned optional params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | self.optional_params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:43:59 | LiteLLM | [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://openaigpt4audc.openai.azure.com \
-H 'api_key: *****' -H 'azure_ad_token: *****' \
-d '{'model': 'bini', 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], 'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}}'
[0m
 | Function: _print_llm_call_debugging_log | Line: 634
DEBUG | Monday | 17/02/2025 | 10:43:59 | openai._base_client | Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true', 'api-key': '<redacted>'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], 'model': 'bini', 'stop': ['\nObservation:'], 'stream': False, 'temperature': 0}, 'extra_json': {}} | Function: _build_request | Line: 460
DEBUG | Monday | 17/02/2025 | 10:43:59 | openai._base_client | Sending HTTP Request: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview | Function: _request | Line: 1000
DEBUG | Monday | 17/02/2025 | 10:44:01 | openai._base_client | HTTP Response: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview "200 OK" Headers({'content-length': '1115', 'content-type': 'application/json', 'apim-request-id': 'f780c10b-0464-4307-8409-33bcc14a698d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '9901eac6-3058-47cd-bcdc-b921e3d0e355', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9998854', 'azureml-model-session': 'd180-20250206103804', 'x-envoy-upstream-service-time': '849', 'x-ms-client-request-id': 'f780c10b-0464-4307-8409-33bcc14a698d', 'date': 'Mon, 17 Feb 2025 08:44:00 GMT'}) | Function: _request | Line: 1039
DEBUG | Monday | 17/02/2025 | 10:44:01 | openai._base_client | request_id: 9901eac6-3058-47cd-bcdc-b921e3d0e355 | Function: _request | Line: 1047
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | RAW RESPONSE:
{"id": "chatcmpl-B1r1MpM0ykGuItlCZIPJdeuUGGBLQ", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file's content\nAction Input: {\"file_path\": \"C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv\"}", "refusal": null, "role": "assistant", "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1739781840, "model": "gpt-4o-2024-05-13", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_65792305e4", "usage": {"completion_tokens": 71, "prompt_tokens": 465, "total_tokens": 536, "completion_tokens_details": null, "prompt_tokens_details": null}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}

 | Function: print_verbose | Line: 298
INFO | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Wrapper: Completed Call, calling success_handler | Function: wrapper | Line: 1084
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Logging Details LiteLLM-Success Call: Cache_hit=None | Function: success_handler | Line: 1014
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | response_cost: 0.0033900000000000002 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | response_cost: 0.0033900000000000002 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Logging Details LiteLLM-Success Call streaming complete | Function: success_handler | Line: 1040
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | response_cost: 0.0033900000000000002 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | [92mRequest to litellm:[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | [92mlitellm.completion(model='azure/bini', messages=[{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}], temperature=0, stop=['\nObservation:'], api_version='2024-02-15-preview', stream=False)[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>] | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | self.optional_params: {} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Translating developer role to system role for non-OpenAI providers. | Function: translate_developer_role_to_system_role | Line: 115
INFO | Monday | 17/02/2025 | 10:44:01 | LiteLLM | 
LiteLLM completion() model= bini; provider = azure | Function: _check_valid_arg | Line: 2896
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | 
LiteLLM: Params passed to completion() {'model': 'bini', 'functions': None, 'function_call': None, 'temperature': 0, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'azure', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': '2024-02-15-preview', 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}]} | Function: _check_valid_arg | Line: 2899
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | 
LiteLLM: Non-Default params passed to completion() {'temperature': 0, 'stream': False, 'stop': ['\nObservation:']} | Function: _check_valid_arg | Line: 2902
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Azure optional params - api_version: api_version=2024-02-15-preview, litellm.api_version=None, os.environ['AZURE_API_VERSION']=2024-02-15-preview | Function: get_optional_params | Line: 3502
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | Final returned optional params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | self.optional_params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:01 | LiteLLM | [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://openaigpt4audc.openai.azure.com \
-H 'api_key: *****' -H 'azure_ad_token: *****' \
-d '{'model': 'bini', 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}], 'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}}'
[0m
 | Function: _print_llm_call_debugging_log | Line: 634
DEBUG | Monday | 17/02/2025 | 10:44:01 | openai._base_client | Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true', 'api-key': '<redacted>'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}], 'model': 'bini', 'stop': ['\nObservation:'], 'stream': False, 'temperature': 0}, 'extra_json': {}} | Function: _build_request | Line: 460
DEBUG | Monday | 17/02/2025 | 10:44:01 | openai._base_client | Sending HTTP Request: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview | Function: _request | Line: 1000
DEBUG | Monday | 17/02/2025 | 10:44:06 | openai._base_client | HTTP Response: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview "200 OK" Headers({'content-length': '2239', 'content-type': 'application/json', 'apim-request-id': '9900bd8c-9875-4373-93fe-20f8ee956265', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'a3f7c01a-86bb-44ad-b14e-24ca6e8babe9', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '9997435', 'azureml-model-session': 'd331-20250124021516', 'x-envoy-upstream-service-time': '3820', 'x-ms-client-request-id': '9900bd8c-9875-4373-93fe-20f8ee956265', 'date': 'Mon, 17 Feb 2025 08:44:05 GMT'}) | Function: _request | Line: 1039
DEBUG | Monday | 17/02/2025 | 10:44:06 | openai._base_client | request_id: a3f7c01a-86bb-44ad-b14e-24ca6e8babe9 | Function: _request | Line: 1047
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | RAW RESPONSE:
{"id": "chatcmpl-B1r1OfTPePZwbuHoVt8agasGGhqJS", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "Thought: I have successfully read the content of the page_base.csv file. Now, I need to refactor the `Element Name` column to logical names based on the provided input.\n\nAction: File Writer Tool\nAction Input: {\"filename\": \"page_base.csv\", \"directory\": \"C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\", \"overwrite\": \"true\", \"content\": \"Element Name,Element Type,Element Path,Action,Value\\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\\nEmailInputField,ID,i0116,Clicked on input,\\nNextButton,ID,idSIButton9,Clicked on input,\\nCheckbox1,XPATH,\\\"//*[@id=\\\"67b1c354b627305207967729-checkbox\\\"]/span[1]/input[1]\\\",Checkbox unchecked,off\\nCheckbox2,XPATH,\\\"//*[@id=\\\"67b1bef2b627305207967706-checkbox\\\"]/span[1]/input[1]\\\",Checkbox unchecked,off\\nCheckbox3,XPATH,\\\"//*[@id=\\\"67ae329cb6273052079672bf-checkbox\\\"]/span[1]/input[1]\\\",Checkbox unchecked,off\\nActionButton,ID,call-Actions-btn,Clicked on Action,\\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\\nLink,XPATH,\\\"//*[@id=\\\"root\\\"]/a[1]\\\",Clicked on a,\"}", "refusal": null, "role": "assistant", "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1739781842, "model": "gpt-4o-2024-05-13", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_f3927aa00d", "usage": {"completion_tokens": 329, "prompt_tokens": 787, "total_tokens": 1116, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}

 | Function: print_verbose | Line: 298
INFO | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Wrapper: Completed Call, calling success_handler | Function: wrapper | Line: 1084
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Logging Details LiteLLM-Success Call: Cache_hit=None | Function: success_handler | Line: 1014
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | response_cost: 0.00887 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | response_cost: 0.00887 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Logging Details LiteLLM-Success Call streaming complete | Function: success_handler | Line: 1040
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | response_cost: 0.00887 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | [92mRequest to litellm:[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | [92mlitellm.completion(model='azure/bini', messages=[{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}, {'role': 'assistant', 'content': 'Thought: I have successfully read the content of the page_base.csv file. Now, I need to refactor the `Element Name` column to logical names based on the provided input.\n\nAction: File Writer Tool\nAction Input: {"filename": "page_base.csv", "directory": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output", "overwrite": "true", "content": "Element Name,Element Type,Element Path,Action,Value\\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\\nEmailInputField,ID,i0116,Clicked on input,\\nNextButton,ID,idSIButton9,Clicked on input,\\nCheckbox1,XPATH,\\"//*[@id=\\"67b1c354b627305207967729-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox2,XPATH,\\"//*[@id=\\"67b1bef2b627305207967706-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox3,XPATH,\\"//*[@id=\\"67ae329cb6273052079672bf-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nActionButton,ID,call-Actions-btn,Clicked on Action,\\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\\nLink,XPATH,\\"//*[@id=\\"root\\"]/a[1]\\",Clicked on a,"}\nObservation: Content successfully written to C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv'}], temperature=0, stop=['\nObservation:'], api_version='2024-02-15-preview', stream=False)[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>] | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | self.optional_params: {} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Translating developer role to system role for non-OpenAI providers. | Function: translate_developer_role_to_system_role | Line: 115
INFO | Monday | 17/02/2025 | 10:44:06 | LiteLLM | 
LiteLLM completion() model= bini; provider = azure | Function: _check_valid_arg | Line: 2896
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | 
LiteLLM: Params passed to completion() {'model': 'bini', 'functions': None, 'function_call': None, 'temperature': 0, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'azure', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': '2024-02-15-preview', 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}, {'role': 'assistant', 'content': 'Thought: I have successfully read the content of the page_base.csv file. Now, I need to refactor the `Element Name` column to logical names based on the provided input.\n\nAction: File Writer Tool\nAction Input: {"filename": "page_base.csv", "directory": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output", "overwrite": "true", "content": "Element Name,Element Type,Element Path,Action,Value\\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\\nEmailInputField,ID,i0116,Clicked on input,\\nNextButton,ID,idSIButton9,Clicked on input,\\nCheckbox1,XPATH,\\"//*[@id=\\"67b1c354b627305207967729-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox2,XPATH,\\"//*[@id=\\"67b1bef2b627305207967706-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox3,XPATH,\\"//*[@id=\\"67ae329cb6273052079672bf-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nActionButton,ID,call-Actions-btn,Clicked on Action,\\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\\nLink,XPATH,\\"//*[@id=\\"root\\"]/a[1]\\",Clicked on a,"}\nObservation: Content successfully written to C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv'}]} | Function: _check_valid_arg | Line: 2899
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | 
LiteLLM: Non-Default params passed to completion() {'temperature': 0, 'stream': False, 'stop': ['\nObservation:']} | Function: _check_valid_arg | Line: 2902
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Azure optional params - api_version: api_version=2024-02-15-preview, litellm.api_version=None, os.environ['AZURE_API_VERSION']=2024-02-15-preview | Function: get_optional_params | Line: 3502
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | Final returned optional params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | self.optional_params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:06 | LiteLLM | [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://openaigpt4audc.openai.azure.com \
-H 'api_key: *****' -H 'azure_ad_token: *****' \
-d '{'model': 'bini', 'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}, {'role': 'assistant', 'content': 'Thought: I have successfully read the content of the page_base.csv file. Now, I need to refactor the `Element Name` column to logical names based on the provided input.\n\nAction: File Writer Tool\nAction Input: {"filename": "page_base.csv", "directory": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output", "overwrite": "true", "content": "Element Name,Element Type,Element Path,Action,Value\\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\\nEmailInputField,ID,i0116,Clicked on input,\\nNextButton,ID,idSIButton9,Clicked on input,\\nCheckbox1,XPATH,\\"//*[@id=\\"67b1c354b627305207967729-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox2,XPATH,\\"//*[@id=\\"67b1bef2b627305207967706-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox3,XPATH,\\"//*[@id=\\"67ae329cb6273052079672bf-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nActionButton,ID,call-Actions-btn,Clicked on Action,\\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\\nLink,XPATH,\\"//*[@id=\\"root\\"]/a[1]\\",Clicked on a,"}\nObservation: Content successfully written to C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv'}], 'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}}'
[0m
 | Function: _print_llm_call_debugging_log | Line: 634
DEBUG | Monday | 17/02/2025 | 10:44:06 | openai._base_client | Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true', 'api-key': '<redacted>'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are automation engineer pro in page base csv.\n. You\'re a seasoned POM automation engineer \n\nYour personal goal is: analyze page base and refactor the element name based on logical csv steps\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: under `Element Name` column change to a logical name based on hole input\n\n\nThis is the expected criteria for your final answer: correct page base csv\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to read the content of the page_base.csv file to analyze the `Element Name` column and refactor the element names based on logical steps.\n\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\page_base.csv"}\nObservation: Element Name,Element Type,Element Path,Action,Value\nSign in with Microsoft 365,ID,login_button,Clicked on Sign in with Microsoft 365,\ni0116,ID,i0116,Clicked on input,\nidsibutton9,ID,idSIButton9,Clicked on input,\ncheckbox_1739781823445,XPATH,"//*[@id=""67b1c354b627305207967729-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781823794,XPATH,"//*[@id=""67b1bef2b627305207967706-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\ncheckbox_1739781824220,XPATH,"//*[@id=""67ae329cb6273052079672bf-checkbox""]/span[1]/input[1]",Checkbox unchecked,off\nAction,ID,call-Actions-btn,Clicked on Action,\nExport to Excel,ID,exportExcel-menuitem,Clicked on Export to Excel,\nexport,ID,interactions-exportToExcel-export-btn,Clicked on export,\na,XPATH,"//*[@id=""root""]/a[1]",Clicked on a,'}, {'role': 'assistant', 'content': 'Thought: I have successfully read the content of the page_base.csv file. Now, I need to refactor the `Element Name` column to logical names based on the provided input.\n\nAction: File Writer Tool\nAction Input: {"filename": "page_base.csv", "directory": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output", "overwrite": "true", "content": "Element Name,Element Type,Element Path,Action,Value\\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\\nEmailInputField,ID,i0116,Clicked on input,\\nNextButton,ID,idSIButton9,Clicked on input,\\nCheckbox1,XPATH,\\"//*[@id=\\"67b1c354b627305207967729-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox2,XPATH,\\"//*[@id=\\"67b1bef2b627305207967706-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nCheckbox3,XPATH,\\"//*[@id=\\"67ae329cb6273052079672bf-checkbox\\"]/span[1]/input[1]\\",Checkbox unchecked,off\\nActionButton,ID,call-Actions-btn,Clicked on Action,\\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\\nLink,XPATH,\\"//*[@id=\\"root\\"]/a[1]\\",Clicked on a,"}\nObservation: Content successfully written to C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\page_base.csv'}], 'model': 'bini', 'stop': ['\nObservation:'], 'stream': False, 'temperature': 0}, 'extra_json': {}} | Function: _build_request | Line: 460
DEBUG | Monday | 17/02/2025 | 10:44:06 | openai._base_client | Sending HTTP Request: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview | Function: _request | Line: 1000
DEBUG | Monday | 17/02/2025 | 10:44:10 | openai._base_client | HTTP Response: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview "200 OK" Headers({'content-length': '1698', 'content-type': 'application/json', 'apim-request-id': '6624598b-2c6c-46f0-b6da-197c2a39dd5d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '0195211b-a50b-47b5-a067-a6e7fc9f2a36', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '9995702', 'azureml-model-session': 'd142-20250211040237', 'x-envoy-upstream-service-time': '2430', 'x-ms-client-request-id': '6624598b-2c6c-46f0-b6da-197c2a39dd5d', 'date': 'Mon, 17 Feb 2025 08:44:09 GMT'}) | Function: _request | Line: 1039
DEBUG | Monday | 17/02/2025 | 10:44:10 | openai._base_client | request_id: 0195211b-a50b-47b5-a067-a6e7fc9f2a36 | Function: _request | Line: 1047
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | RAW RESPONSE:
{"id": "chatcmpl-B1r1Tc08hVCOnvaoj6tOZeKLlhz6h", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "```\nThought: I now know the final answer\nFinal Answer: Element Name,Element Type,Element Path,Action,Value\nSignInWithMicrosoft365Button,ID,login_button,Clicked on Sign in with Microsoft 365,\nEmailInputField,ID,i0116,Clicked on input,\nNextButton,ID,idSIButton9,Clicked on input,\nCheckbox1,XPATH,\"//*[@id=\"\"67b1c354b627305207967729-checkbox\"\"]/span[1]/input[1]\",Checkbox unchecked,off\nCheckbox2,XPATH,\"//*[@id=\"\"67b1bef2b627305207967706-checkbox\"\"]/span[1]/input[1]\",Checkbox unchecked,off\nCheckbox3,XPATH,\"//*[@id=\"\"67ae329cb6273052079672bf-checkbox\"\"]/span[1]/input[1]\",Checkbox unchecked,off\nActionButton,ID,call-Actions-btn,Clicked on Action,\nExportToExcelMenuItem,ID,exportExcel-menuitem,Clicked on Export to Excel,\nExportButton,ID,interactions-exportToExcel-export-btn,Clicked on export,\nLink,XPATH,\"//*[@id=\"\"root\"\"]/a[1]\",Clicked on a,\n```", "refusal": null, "role": "assistant", "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1739781847, "model": "gpt-4o-2024-05-13", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_65792305e4", "usage": {"completion_tokens": 247, "prompt_tokens": 1146, "total_tokens": 1393, "completion_tokens_details": null, "prompt_tokens_details": null}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}

 | Function: print_verbose | Line: 298
INFO | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Wrapper: Completed Call, calling success_handler | Function: wrapper | Line: 1084
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Logging Details LiteLLM-Success Call: Cache_hit=None | Function: success_handler | Line: 1014
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | response_cost: 0.009435 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | response_cost: 0.009435 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Logging Details LiteLLM-Success Call streaming complete | Function: success_handler | Line: 1040
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | response_cost: 0.009435 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
WARNING | Monday | 17/02/2025 | 10:44:10 | opentelemetry.trace | Overriding of current TracerProvider is not allowed | Function: _set_tracer_provider | Line: 537
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | [92mRequest to litellm:[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | [92mlitellm.completion(model='azure/bini', messages=[{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}], temperature=0, stop=['\nObservation:'], api_version='2024-02-15-preview', stream=False)[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>], not adding again.. | Function: _add_custom_logger_to_list | Line: 173
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>], not adding again.. | Function: _add_custom_logger_to_list | Line: 173
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F6FF0>] | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | self.optional_params: {} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Translating developer role to system role for non-OpenAI providers. | Function: translate_developer_role_to_system_role | Line: 115
INFO | Monday | 17/02/2025 | 10:44:10 | LiteLLM | 
LiteLLM completion() model= bini; provider = azure | Function: _check_valid_arg | Line: 2896
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | 
LiteLLM: Params passed to completion() {'model': 'bini', 'functions': None, 'function_call': None, 'temperature': 0, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'azure', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': '2024-02-15-preview', 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}]} | Function: _check_valid_arg | Line: 2899
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | 
LiteLLM: Non-Default params passed to completion() {'temperature': 0, 'stream': False, 'stop': ['\nObservation:']} | Function: _check_valid_arg | Line: 2902
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Azure optional params - api_version: api_version=2024-02-15-preview, litellm.api_version=None, os.environ['AZURE_API_VERSION']=2024-02-15-preview | Function: get_optional_params | Line: 3502
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | Final returned optional params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | self.optional_params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:10 | LiteLLM | [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://openaigpt4audc.openai.azure.com \
-H 'api_key: *****' -H 'azure_ad_token: *****' \
-d '{'model': 'bini', 'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}], 'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}}'
[0m
 | Function: _print_llm_call_debugging_log | Line: 634
DEBUG | Monday | 17/02/2025 | 10:44:10 | openai._base_client | Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true', 'api-key': '<redacted>'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}], 'model': 'bini', 'stop': ['\nObservation:'], 'stream': False, 'temperature': 0}, 'extra_json': {}} | Function: _build_request | Line: 460
DEBUG | Monday | 17/02/2025 | 10:44:10 | openai._base_client | Sending HTTP Request: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview | Function: _request | Line: 1000
DEBUG | Monday | 17/02/2025 | 10:44:12 | openai._base_client | HTTP Response: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview "200 OK" Headers({'content-length': '1084', 'content-type': 'application/json', 'apim-request-id': '605556db-b0a0-4c61-a4a2-026e91f033a8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'a75d00a8-2d43-4639-8219-01d1f2f5f637', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '9994249', 'azureml-model-session': 'd184-20250206113023', 'x-envoy-upstream-service-time': '918', 'x-ms-client-request-id': '605556db-b0a0-4c61-a4a2-026e91f033a8', 'date': 'Mon, 17 Feb 2025 08:44:11 GMT'}) | Function: _request | Line: 1039
DEBUG | Monday | 17/02/2025 | 10:44:12 | openai._base_client | request_id: a75d00a8-2d43-4639-8219-01d1f2f5f637 | Function: _request | Line: 1047
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | RAW RESPONSE:
{"id": "chatcmpl-B1r1XybcqVMwpz2s9ntfkwwUe0V2r", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "```\nThought: I need to read the content of the test plan file to understand the details and convert it into a pytest script.\nAction: Read a file's content\nAction Input: {\"file_path\": \"C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\test_code.py\"}", "refusal": null, "role": "assistant", "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1739781851, "model": "gpt-4o-2024-05-13", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_65792305e4", "usage": {"completion_tokens": 65, "prompt_tokens": 753, "total_tokens": 818, "completion_tokens_details": null, "prompt_tokens_details": null}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}

 | Function: print_verbose | Line: 298
INFO | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Wrapper: Completed Call, calling success_handler | Function: wrapper | Line: 1084
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Logging Details LiteLLM-Success Call: Cache_hit=None | Function: success_handler | Line: 1014
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | response_cost: 0.00474 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | response_cost: 0.00474 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Logging Details LiteLLM-Success Call streaming complete | Function: success_handler | Line: 1040
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | [92mRequest to litellm:[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | [92mlitellm.completion(model='azure/bini', messages=[{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}, {'role': 'assistant', 'content': '```\nThought: I need to read the content of the test plan file to understand the details and convert it into a pytest script.\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\test_code.py"}\nObservation: \n        import pytest\nfrom qasharedinfra.devices.audc.smarttap.smarttap import SmartTap\nimport coreinfra.core.environment.environment_variables as env\nfrom coreinfra.services.selenium.mappedselenium import MappedSelenium\nfrom coreinfra.services.selenium.seleniumwebelement import Actions\n\nfrom qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils\n\nHEADLESS = False\nst: SmartTap = env.devices[\'Device_1\']\nlog = env.logger\n\n\n@pytest.fixture(scope=\'module\', autouse=True)\ndef init_globals() -> None:\n\n    st.logger_.info(\'\n******** Module (Script) Setup ********\')\n    bini = IRBiniUtils()\n    st.test_prerequisites(selenium=True, headless=HEADLESS)\n    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen\n\n    yield bini\n\n    st.logger.info(\'******** Module (Script) TearDown ********\')\n    st.selenium.finalize()\n\n\n@pytest.fixture(scope=\'function\', autouse=True)\ndef setup_and_teardown() -> None:\n    st.logger_.info(\'******** Test Setup ********\')\n\n    yield\n\n    st.logger_.info(\'******** Test TearDown ********\')\n\n@pytest.fixture\ndef driver() -> MappedSelenium:\n    return st.selenium\n    \n    \n        class TestNone:\n\n            def test_None(self, driver) -> None:\n                driver.get_mapped_element(\'Sign in with Microsoft 365\').action(Actions.CLICK)\ndriver.get_mapped_element(\'i0116\').action(Actions.CLICK)\ndriver.get_mapped_element(\'idsibutton9\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Action\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Export to Excel\').action(Actions.CLICK)\ndriver.get_mapped_element(\'export\').action(Actions.CLICK)\ndriver.get_mapped_element(\'a\').action(Actions.CLICK)'}], temperature=0, stop=['\nObservation:'], api_version='2024-02-15-preview', stream=False)[0m | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | 
 | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>], not adding again.. | Function: _add_custom_logger_to_list | Line: 173
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | response_cost: 0.00474 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F7050>], not adding again.. | Function: _add_custom_logger_to_list | Line: 173
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x00000171E04F6FF0>] | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | self.optional_params: {} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Translating developer role to system role for non-OpenAI providers. | Function: translate_developer_role_to_system_role | Line: 115
INFO | Monday | 17/02/2025 | 10:44:12 | LiteLLM | 
LiteLLM completion() model= bini; provider = azure | Function: _check_valid_arg | Line: 2896
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | 
LiteLLM: Params passed to completion() {'model': 'bini', 'functions': None, 'function_call': None, 'temperature': 0, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'azure', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': '2024-02-15-preview', 'parallel_tool_calls': None, 'drop_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}, {'role': 'assistant', 'content': '```\nThought: I need to read the content of the test plan file to understand the details and convert it into a pytest script.\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\test_code.py"}\nObservation: \n        import pytest\nfrom qasharedinfra.devices.audc.smarttap.smarttap import SmartTap\nimport coreinfra.core.environment.environment_variables as env\nfrom coreinfra.services.selenium.mappedselenium import MappedSelenium\nfrom coreinfra.services.selenium.seleniumwebelement import Actions\n\nfrom qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils\n\nHEADLESS = False\nst: SmartTap = env.devices[\'Device_1\']\nlog = env.logger\n\n\n@pytest.fixture(scope=\'module\', autouse=True)\ndef init_globals() -> None:\n\n    st.logger_.info(\'\n******** Module (Script) Setup ********\')\n    bini = IRBiniUtils()\n    st.test_prerequisites(selenium=True, headless=HEADLESS)\n    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen\n\n    yield bini\n\n    st.logger.info(\'******** Module (Script) TearDown ********\')\n    st.selenium.finalize()\n\n\n@pytest.fixture(scope=\'function\', autouse=True)\ndef setup_and_teardown() -> None:\n    st.logger_.info(\'******** Test Setup ********\')\n\n    yield\n\n    st.logger_.info(\'******** Test TearDown ********\')\n\n@pytest.fixture\ndef driver() -> MappedSelenium:\n    return st.selenium\n    \n    \n        class TestNone:\n\n            def test_None(self, driver) -> None:\n                driver.get_mapped_element(\'Sign in with Microsoft 365\').action(Actions.CLICK)\ndriver.get_mapped_element(\'i0116\').action(Actions.CLICK)\ndriver.get_mapped_element(\'idsibutton9\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Action\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Export to Excel\').action(Actions.CLICK)\ndriver.get_mapped_element(\'export\').action(Actions.CLICK)\ndriver.get_mapped_element(\'a\').action(Actions.CLICK)'}]} | Function: _check_valid_arg | Line: 2899
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | 
LiteLLM: Non-Default params passed to completion() {'temperature': 0, 'stream': False, 'stop': ['\nObservation:']} | Function: _check_valid_arg | Line: 2902
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Azure optional params - api_version: api_version=2024-02-15-preview, litellm.api_version=None, os.environ['AZURE_API_VERSION']=2024-02-15-preview | Function: get_optional_params | Line: 3502
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | Final returned optional params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: print_verbose | Line: 298
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | self.optional_params: {'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}} | Function: update_environment_variables | Line: 377
DEBUG | Monday | 17/02/2025 | 10:44:12 | LiteLLM | [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://openaigpt4audc.openai.azure.com \
-H 'api_key: *****' -H 'azure_ad_token: *****' \
-d '{'model': 'bini', 'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}, {'role': 'assistant', 'content': '```\nThought: I need to read the content of the test plan file to understand the details and convert it into a pytest script.\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\test_code.py"}\nObservation: \n        import pytest\nfrom qasharedinfra.devices.audc.smarttap.smarttap import SmartTap\nimport coreinfra.core.environment.environment_variables as env\nfrom coreinfra.services.selenium.mappedselenium import MappedSelenium\nfrom coreinfra.services.selenium.seleniumwebelement import Actions\n\nfrom qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils\n\nHEADLESS = False\nst: SmartTap = env.devices[\'Device_1\']\nlog = env.logger\n\n\n@pytest.fixture(scope=\'module\', autouse=True)\ndef init_globals() -> None:\n\n    st.logger_.info(\'\n******** Module (Script) Setup ********\')\n    bini = IRBiniUtils()\n    st.test_prerequisites(selenium=True, headless=HEADLESS)\n    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen\n\n    yield bini\n\n    st.logger.info(\'******** Module (Script) TearDown ********\')\n    st.selenium.finalize()\n\n\n@pytest.fixture(scope=\'function\', autouse=True)\ndef setup_and_teardown() -> None:\n    st.logger_.info(\'******** Test Setup ********\')\n\n    yield\n\n    st.logger_.info(\'******** Test TearDown ********\')\n\n@pytest.fixture\ndef driver() -> MappedSelenium:\n    return st.selenium\n    \n    \n        class TestNone:\n\n            def test_None(self, driver) -> None:\n                driver.get_mapped_element(\'Sign in with Microsoft 365\').action(Actions.CLICK)\ndriver.get_mapped_element(\'i0116\').action(Actions.CLICK)\ndriver.get_mapped_element(\'idsibutton9\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Action\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Export to Excel\').action(Actions.CLICK)\ndriver.get_mapped_element(\'export\').action(Actions.CLICK)\ndriver.get_mapped_element(\'a\').action(Actions.CLICK)'}], 'temperature': 0, 'stream': False, 'stop': ['\nObservation:'], 'extra_body': {}}'
[0m
 | Function: _print_llm_call_debugging_log | Line: 634
DEBUG | Monday | 17/02/2025 | 10:44:12 | openai._base_client | Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true', 'api-key': '<redacted>'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Test Plan and Automation Engineer specializing in function analysis.\n. You\'re a seasoned test plan engineer with expertise in mapping test functions and ensuring they align with automation requirements.\n\nYour personal goal is: Read and analyze the provided test plan by dynamically extracting function details and mapping them to the pytest format.\n\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Read a file\'s content\nTool Arguments: {\'file_path\': {\'description\': \'Mandatory file full path to read the file\', \'type\': \'str\'}}\nTool Description: A tool that reads file content. The default file is C:\\Users\\evgenyp\\PycharmProjects\\codegen\\output\\test_code.py, but you can provide a different \'file_path\' parameter to read another file.\nTool Name: File Writer Tool\nTool Arguments: {\'filename\': {\'description\': None, \'type\': \'str\'}, \'directory\': {\'description\': None, \'type\': \'Union[str, NoneType]\'}, \'overwrite\': {\'description\': None, \'type\': \'str\'}, \'content\': {\'description\': None, \'type\': \'str\'}}\nTool Description: A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input.\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Read a file\'s content, File Writer Tool], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': "\nCurrent Task: Convert the test plan into a functional pytest script using the specified code format logic.\n**Test Plan:** Based on the `test_plan` provided from the tool.\n**Task:**\n  - If the device is set to `smarttap` or `st`, all imports should be:\n    ```\n    from qasharedinfra.infra.smarttap.general_utils import get_file_size\n    ```\n    and the device instance should be:\n    ```\n    st: SmartTap = env.devices['Device_1']\n    ```\n  - If the device is set to `mi`, all imports should include `meetinginsights` instead of `smarttap`:\n    ```\n    from qasharedinfra.infra.meetinginsights.selenium.utils.custom_exceptions import ElementIsClickableException\n    ```\n    and replace `st` with:\n    ```\n    mi: MeetingInsightsSaaS = env.devices['Device_1']\n    ```\n\n**Code Format:** `{original_code}`\n**Important Guidelines:**\n  1. Always log each assertion. Example:\n     ```\n     assert <body>, log.bug('this is a bug')\n     ```\n  2. Replace Seleniums `send_keys()` with `inject_text()`.\n  3. The number of tests must match the test plan provided.\n  4. Maintain simple and clean code logic.\n  5. Each test must contain a docstring.\n\n\nThis is the expected criteria for your final answer: A Python script with pytest tests.\n\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:"}, {'role': 'assistant', 'content': '```\nThought: I need to read the content of the test plan file to understand the details and convert it into a pytest script.\nAction: Read a file\'s content\nAction Input: {"file_path": "C:\\\\Users\\\\evgenyp\\\\PycharmProjects\\\\codegen\\\\output\\\\test_code.py"}\nObservation: \n        import pytest\nfrom qasharedinfra.devices.audc.smarttap.smarttap import SmartTap\nimport coreinfra.core.environment.environment_variables as env\nfrom coreinfra.services.selenium.mappedselenium import MappedSelenium\nfrom coreinfra.services.selenium.seleniumwebelement import Actions\n\nfrom qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils\n\nHEADLESS = False\nst: SmartTap = env.devices[\'Device_1\']\nlog = env.logger\n\n\n@pytest.fixture(scope=\'module\', autouse=True)\ndef init_globals() -> None:\n\n    st.logger_.info(\'\n******** Module (Script) Setup ********\')\n    bini = IRBiniUtils()\n    st.test_prerequisites(selenium=True, headless=HEADLESS)\n    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen\n\n    yield bini\n\n    st.logger.info(\'******** Module (Script) TearDown ********\')\n    st.selenium.finalize()\n\n\n@pytest.fixture(scope=\'function\', autouse=True)\ndef setup_and_teardown() -> None:\n    st.logger_.info(\'******** Test Setup ********\')\n\n    yield\n\n    st.logger_.info(\'******** Test TearDown ********\')\n\n@pytest.fixture\ndef driver() -> MappedSelenium:\n    return st.selenium\n    \n    \n        class TestNone:\n\n            def test_None(self, driver) -> None:\n                driver.get_mapped_element(\'Sign in with Microsoft 365\').action(Actions.CLICK)\ndriver.get_mapped_element(\'i0116\').action(Actions.CLICK)\ndriver.get_mapped_element(\'idsibutton9\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Action\').action(Actions.CLICK)\ndriver.get_mapped_element(\'Export to Excel\').action(Actions.CLICK)\ndriver.get_mapped_element(\'export\').action(Actions.CLICK)\ndriver.get_mapped_element(\'a\').action(Actions.CLICK)'}], 'model': 'bini', 'stop': ['\nObservation:'], 'stream': False, 'temperature': 0}, 'extra_json': {}} | Function: _build_request | Line: 460
DEBUG | Monday | 17/02/2025 | 10:44:12 | openai._base_client | Sending HTTP Request: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview | Function: _request | Line: 1000
DEBUG | Monday | 17/02/2025 | 10:44:18 | openai._base_client | HTTP Response: POST https://openaigpt4audc.openai.azure.com/openai/deployments/bini/chat/completions?api-version=2024-02-15-preview "200 OK" Headers({'content-length': '2998', 'content-type': 'application/json', 'apim-request-id': '12f847c3-0998-40ee-ab3a-94a9a9e3f0fd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'd3e8547e-af98-4d17-b756-2253f4f79460', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '9992307', 'azureml-model-session': 'd039-20241219040306', 'x-envoy-upstream-service-time': '5310', 'x-ms-client-request-id': '12f847c3-0998-40ee-ab3a-94a9a9e3f0fd', 'date': 'Mon, 17 Feb 2025 08:44:17 GMT'}) | Function: _request | Line: 1039
DEBUG | Monday | 17/02/2025 | 10:44:18 | openai._base_client | request_id: d3e8547e-af98-4d17-b756-2253f4f79460 | Function: _request | Line: 1047
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | RAW RESPONSE:
{"id": "chatcmpl-B1r1ZM49iRzxVw1lg5RfVB7926dDS", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "```\nThought: I now have the content of the test plan. I need to convert this content into a functional pytest script based on the provided guidelines.\nFinal Answer: \n\nimport pytest\nfrom qasharedinfra.infra.smarttap.general_utils import get_file_size\nfrom qasharedinfra.devices.audc.smarttap.smarttap import SmartTap\nimport coreinfra.core.environment.environment_variables as env\nfrom coreinfra.services.selenium.mappedselenium import MappedSelenium\nfrom coreinfra.services.selenium.seleniumwebelement import Actions\n\nfrom qasharedinfra.infra.smarttap.selenium.utils.bini_utils import IRBiniUtils\n\nHEADLESS = False\nst: SmartTap = env.devices['Device_1']\nlog = env.logger\n\n\n@pytest.fixture(scope='module', autouse=True)\ndef init_globals() -> None:\n    \"\"\"\n    Module setup and teardown\n    \"\"\"\n    st.logger_.info('******** Module (Script) Setup ********')\n    bini = IRBiniUtils()\n    st.test_prerequisites(selenium=True, headless=HEADLESS)\n    st.ui.utils.st_selenium_go_to_screen_in_current_window(st.selenium, st.st_screens)  # add screen\n\n    yield bini\n\n    st.logger.info('******** Module (Script) TearDown ********')\n    st.selenium.finalize()\n\n\n@pytest.fixture(scope='function', autouse=True)\ndef setup_and_teardown() -> None:\n    \"\"\"\n    Test setup and teardown\n    \"\"\"\n    st.logger_.info('******** Test Setup ********')\n\n    yield\n\n    st.logger_.info('******** Test TearDown ********')\n\n@pytest.fixture\ndef driver() -> MappedSelenium:\n    return st.selenium\n    \n    \nclass TestNone:\n\n    def test_None(self, driver) -> None:\n        \"\"\"\n        Test case for None\n        \"\"\"\n        driver.get_mapped_element('Sign in with Microsoft 365').action(Actions.CLICK)\n        driver.get_mapped_element('i0116').action(Actions.CLICK)\n        driver.get_mapped_element('idsibutton9').action(Actions.CLICK)\n        driver.get_mapped_element('Action').action(Actions.CLICK)\n        driver.get_mapped_element('Export to Excel').action(Actions.CLICK)\n        driver.get_mapped_element('export').action(Actions.CLICK)\n        driver.get_mapped_element('a').action(Actions.CLICK)\n```", "refusal": null, "role": "assistant", "audio": null, "function_call": null, "tool_calls": null}, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}], "created": 1739781853, "model": "gpt-4o-2024-05-13", "object": "chat.completion", "service_tier": null, "system_fingerprint": "fp_65792305e4", "usage": {"completion_tokens": 481, "prompt_tokens": 1221, "total_tokens": 1702, "completion_tokens_details": null, "prompt_tokens_details": null}, "prompt_filter_results": [{"prompt_index": 0, "content_filter_results": {"hate": {"filtered": false, "severity": "safe"}, "self_harm": {"filtered": false, "severity": "safe"}, "sexual": {"filtered": false, "severity": "safe"}, "violence": {"filtered": false, "severity": "safe"}}}]}

 | Function: print_verbose | Line: 298
INFO | Monday | 17/02/2025 | 10:44:18 | LiteLLM | Wrapper: Completed Call, calling success_handler | Function: wrapper | Line: 1084
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | Logging Details LiteLLM-Success Call: Cache_hit=None | Function: success_handler | Line: 1014
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | response_cost: 0.01332 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | response_cost: 0.01332 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | Logging Details LiteLLM-Success Call streaming complete | Function: success_handler | Line: 1040
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | completion_response _select_model_name_for_cost_calc: azure/gpt-4o-2024-05-13 | Function: completion_cost | Line: 563
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | response_cost: 0.01332 | Function: _response_cost_calculator | Line: 846
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-2024-05-13', 'combined_model_name': 'azure/gpt-4o-2024-05-13', 'stripped_model_name': 'gpt-4o-2024-05-13', 'combined_stripped_model_name': 'azure/gpt-4o-2024-05-13', 'custom_llm_provider': 'azure'} | Function: _get_model_info_helper | Line: 4166
DEBUG | Monday | 17/02/2025 | 10:44:18 | LiteLLM | model_info: {'key': 'azure/gpt-4o-2024-05-13', 'max_tokens': 4096, 'max_input_tokens': 128000, 'max_output_tokens': 4096, 'input_cost_per_token': 5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.5e-05, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'azure', 'mode': 'chat', 'supports_system_messages': None, 'supports_response_schema': None, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': True, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': None, 'rpm': None} | Function: get_model_info | Line: 4441
